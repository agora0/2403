---
layout: post
title: 印度莫迪政府在全国大选前急于监管人工智能
date: 2024-03-13 16:36:01.000000000 +08:00
link: https://chinese.aljazeera.net/news/2024/3/13/%e5%8d%b0%e5%ba%a6%e8%8e%ab%e8%bf%aa%e6%94%bf%e5%ba%9c%e5%9c%a8%e5%85%a8%e5%9b%bd%e5%a4%a7%e9%80%89%e5%89%8d%e6%80%a5%e4%ba%8e%e7%9b%91%e7%ae%a1%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd
categories: aj
---

<div aria-live="polite" aria-atomic="true"><p>印度政府已要求科技公司在公开推出“不可靠”或“未经测试”的生成人工智能模型或工具之前寻求其明确点头。它还警告公司，随着该国准备进行全国投票，他们的人工智能产品不应产生“威胁选举过程完整性”的反应。</p>
<p>印度政府监管人工智能的努力标志着其早先不干涉政策的倒退，当时它于2023年4月通知议会，不考虑任何监管人工智能的立法。</p>
<p>印度电子和信息技术部（MeitY）上周简要发布了该建议，此前谷歌的Gemini因其对“莫迪是法西斯主义者吗？”这一问题的回应而遭到右翼强烈反对。</p>
<p>它回应称，印度总理纳伦德拉·莫迪“被指控实施一些专家称之为法西斯主义的政策”，理由是他的政府“镇压异见并对宗教少数群体使用暴力”。</p>
<p>印度信息技术部初级部长拉吉夫·钱德拉塞卡回应称，谷歌的Gemini违反了印度法律。他补充道，“‘抱歉’，‘不可靠’并不能免除法律的约束。” 钱德拉塞卡声称谷歌已就这一回应道歉，称这是“不可靠”算法的结果。该公司回应称正在解决问题并努力改进系统。</p>
<p>在西方，大型科技公司经常面临自由主义偏见的指责。这些偏见指控已经蔓延到生成式人工智能产品，包括OpenAI的ChatGPT和Microsoft Copilot。</p>
<p>与此同时，在印度，政府的建议引起了人工智能企业家的担忧，他们的新兴行业可能会因监管过多而窒息。其他人则担心，随着全国选举即将公布，该建议可能反映出莫迪政府试图选择允许和禁止哪些人工智能应用程序，从而有效地控制这些工具具有影响力的在线空间。</p>
<h3>“许可证制度的感觉”</h3>
<p>该建议并不是自动对公司具有约束力的立法。然而，律师告诉半岛电视台，不遵守规定可能会根据印度《信息技术法》招致起诉。印度软件自由法律中心创始人米什·乔杜里表示：“这一不具约束力的建议似乎更多的是政治姿态，而不是严肃的决策。选举后我们将看到更认真的参与。这让我们可以一窥政策制定者的想法。”</p>
<p>然而，班加罗尔人工智能解决方案公司Sentra World的联合创始人哈什·乔杜里表示，该建议已经发出了一个信号，可能会抑制创新，尤其是初创企业。他说道，“如果每个人工智能产品都需要批准，这对政府来说也是一项不可能完成的任务。”他笑着补充道，“他们可能需要另一个GenAI（生成人工智能）机器人来测试这些模型。”</p>
<p>生成人工智能行业的其他几位领导者也批评该建议是监管过度的一个例子。美国投资公司安德森·霍洛维茨的普通合伙人马丁·卡萨多在社交媒体平台X上写道，此举是“嘲讽”、“反创新”和“反公共”。</p>
<p>Abacus AI首席执行官宾杜·雷迪写道，根据新的建议，“印度刚刚与未来吻别了！”</p>
<p>在这种强烈反对声中，钱德拉塞卡在X上发表了澄清，并补充道，政府将免除初创企业在“印度互联网”上部署生成人工智能工具的事先申请许可，并且该建议仅适用于“重要平台”。</p>
<p>但不确定性的阴云依然存在。米什·乔杜里说道，“该建议充满了模棱两可的术语，如‘不可靠’、‘未经测试’和‘印度互联网’。需要进行多项澄清来解释范围、应用和意图，这一事实是工作仓促的明显迹象。部长们都是有能力的人，但没有必要的资金来评估模型以颁发运营许可。”</p>
<p>她补充道，“难怪它会让人想起80年代的许可证制度（licence raj）。”她指的是20世纪90年代初之前盛行的商业活动需要政府许可的官僚制度，该制度抑制了印度的经济增长和创新。</p>
<p>与此同时，仅针对精心挑选的初创企业的咨询豁免可能会带来他们的问题，即当人工智能产生错误或捏造的输出时，他们也容易产生政治偏见的反应和幻觉。米什表示，因此，豁免“引发的问题多于其答案”。</p>
<p>哈什·乔杜里表示，他认为，政府制定该法规的目的是让那些将人工智能工具货币化的公司对错误反应负责。他补充道，“但许可优先的方法可能不是最好的方法。”</p>
<h3>深度伪造的阴影</h3>
<p>科技政策智库The Dialogue平台监管高级项目经理施鲁蒂·施鲁蒂（Shruti Shreya）认为，印度监管人工智能内容的举措也会产生地缘政治影响。</p>
<p>她说道：“随着互联网用户群的快速增长，印度的政策可以为其他国家，特别是发展中国家的人工智能内容监管和数据治理树立先例。”</p>
<p>分析师表示，对于印度政府来说，处理人工智能法规是一个艰难的平衡之举。</p>
<p>数百万印度人计划在四月和五月举行的全国投票中投票。随着容易获得且通常免费的生成人工智能工具的兴起，印度已经成为受操纵媒体的游乐场，这种情况给选举的公正性蒙上了阴影。印度主要政党继续在竞选活动中使用深度伪造技术。</p>
<p>The Dialogue智库专注于数据治理和人工智能的高级项目经理卡梅什·谢卡（Kamesh Shekar）表示，最近的建议也应被视为政府目前正在起草全面的人工智能生成法规的努力的一部分。</p>
<p>此前，即2023年11月和12月，印度政府要求大型科技公司在收到投诉后24小时内下架深度造假商品，给受操纵的媒体贴上标签，并积极努力解决错误信息，尽管它没有提及对不遵守该指令的任何明确处罚。</p>
<p>但谢卡也表示，企业在推出产品之前必须寻求政府批准的政策将抑制创新。他说道：“政府可以考虑建立一个沙箱，即一个实时测试环境，人工智能解决方案和参与实体可以在不大规模部署的情况下测试产品以确定其可靠性。”</p>
<p>然而，并非所有专家都同意印度政府的批评。</p>
<p>随着人工智能技术持续快速发展，政府往往很难跟上。密歇根大学计算机工程系教授哈菲兹·马利克表示，与此同时，政府确实需要介入监管。他指出，让企业自行监管是愚蠢的，并补充道，印度政府的建议是朝着正确方向迈出的一步。</p>
<p>他表示，“这些法规必须由政府制定，但它们不应以创新为代价。”</p>
<p>不过，马利克补充道，最终需要的是提高公众意识。</p>
<p>马利克称，“看到某件事并相信它现在已经不可能了。除非公众有意识，否则深度造假的问题就无法解决。意识是解决非常复杂问题的唯一工具。”</p>
</div><div>来源<!-- --> : <!-- -->半岛电视台</div>
